import networkx as nx
from networkx.algorithms import bipartite
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import numpy as np
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
# you need to have tensorflow 
from stellargraph.data import UniformRandomMetaPathWalk
from stellargraph import StellarGraph

__________________________________________________________________________________________________________________________________________________
Steps Followed:

Read Graph from the given movie_actor_network.csv note that the graph is bipartite graph

using stellergaph and gensim packages, get the dense representation(128dimensional vector) of every node in the graph

Apply Clustering Algorithm to group similar actors

a. For this task consider only the actor nodes
b. Apply any clustering algorithm of your choice
c. Choose the number of clusters for which you have maximum score of  ùê∂ùëúùë†ùë°1‚àóùê∂ùëúùë†ùë°2 

Cost1 =  1ùëÅ‚àëeach cluster i(number of nodes in the largest connected component in the graph with the actor nodes and its movie neighbours in cluster i)(total number of nodes in that cluster i)  where N= number of clusters



Cost2 =  1ùëÅ‚àëeach cluster i(sum of degress of actor nodes in the graph with the actor nodes and its movie neighbours in cluster i)(number of unique movie nodes in the graph with the actor nodes and its movie neighbours in cluster i)  where N= number of clusters

 for number_of_clusters in [3, 5, 10, 30, 50, 100, 200, 500]:
     algo = clustering_algorith(clusters=number_of_clusters)
     # you will be passing a matrix of size N*d where N number of actor nodes and d is dimension from gensim
     algo.fit(the dense vectors of actor nodes) 
     computer the metric Cost = Cost1*Cost2
 return number_of_clusters which have maximum Cost
 
d. Fit the clustering algorithm with the opimal number_of_clusters and get the cluster number for each node
e. Convert the d-dimensional dense vectors of nodes into 2-dimensional using dimensionality reduction techniques (preferably TSNE)
f. Plot the 2d scatter plot, with the node vectors after step e and give colors to nodes such that same cluster nodes will have same color

Apply Clustering Algorithm to group similar movies

a. for this task consider only the movie nodes

b. apply any clustering algorithm of your choice

c. choose the number of clusters for which you have maximum score of  ùê∂ùëúùë†ùë°1‚àóùê∂ùëúùë†ùë°2 

Cost1 =  1ùëÅ‚àëeach cluster i(number of nodes in the largest connected component in the graph with the movie nodes and its actor neighbours in cluster i)(total number of nodes in that cluster i)  where N= number of clusters


Cost2 =  1ùëÅ‚àëeach cluster i(sum of degress of movie nodes in the graph with the movie nodes and its actor neighbours in cluster i)(number of unique actor nodes in the graph with the movie nodes and its actor neighbours in cluster i)  where N= number of clusters

 for number_of_clusters in [3, 5, 10, 30, 50, 100, 200, 500]:
     algo = clustering_algorith(clusters=number_of_clusters)
     # you will be passing a matrix of size N*d where N number of actor nodes and d is dimension from gensim
     algo.fit(the dense vectors of actor nodes) 
     computer the metric Cost = Cost1*Cost2
 return number_of_clusters which have maximum Cost
 
d. Fit the clustering algorithm with the opimal number_of_clusters and get the cluster number for each node
e. Convert the d-dimensional dense vectors of nodes into 2-dimensional using dimensionality reduction techniques (preferably TSNE)
f. Plot the 2d scatter plot, with the node vectors after step e and give colors to nodes such that same cluster nodes will have same color

_________________________________________________________________________________________________________________________________________________________________________

data=pd.read_csv(r'D:\AI & ML\Assignments\14. Clustering On Graph Dataset\Files\movie_actor_network.csv', index_col=False, names=['movie','actor'])

edges = [tuple(x) for x in data.values.tolist()]

B = nx.Graph()
B.add_nodes_from(data['movie'].unique(), bipartite=0, label='movie')
B.add_nodes_from(data['actor'].unique(), bipartite=1, label='actor')
B.add_edges_from(edges, label='acted')

A = list(nx.connected_component_subgraphs(B))[0]
print(A)
print("number of nodes", A.number_of_nodes())
print("number of edges", A.number_of_edges())

l, r = nx.bipartite.sets(A)
pos = {}
pos.update((node, (1, index)) for index, node in enumerate(l))
pos.update((node, (2, index)) for index, node in enumerate(r))
nx.draw(A, pos=pos, with_labels=True)
plt.show()

movies = []
actors = []
for i in A.nodes():
    if 'm' in i:
        movies.append(i)
    if 'a' in i:
        actors.append(i)
print('number of movies ', len(movies))
print('number of actors ', len(actors))



# Create the random walker
rw = UniformRandomMetaPathWalk(StellarGraph(A))

# specify the metapath schemas as a list of lists of node types.
metapaths = [
    ["movie", "actor", "movie"],
    ["actor", "movie", "actor"]
]

walks = rw.run(nodes=list(A.nodes()), # root nodes
               length=100,  # maximum length of a random walk
               n=1,        # number of random walks per root node 
             metapaths=metapaths
              )

print("Number of random walks: {}".format(len(walks)))

from gensim.models import Word2Vec
model = Word2Vec(walks, size=128, window=5)

model.wv.vectors.shape  # 128-dimensional vector for each node in the graph


________________________________________________________________________________________________________________________________________________________
## Main Implementation


All_cost=[]
Sorted_cost=[]
# List with different cluster numbers
number_of_cluster = [3, 5 ,10, 30, 50, 100, 200, 500]
for index,i in enumerate(number_of_cluster):
    Cost1=0
    Cost2=0
    algo =KMeans(n_clusters=i)
    C=algo.fit(model[actors])
    clusters_data={}
    # Zipping actors nodes with labels so we can separate actors on basis of labels and get the list of actors in specific cluster number
    for j,k in zip(actors,C.labels_):
        clusters_data.setdefault(k+1, []).append(j)
    for l in clusters_data.keys():
        clustered_data=[]
        clustered_data.append(clusters_data.get(l))    
        # Creating a blank graph
        U=nx.Graph()
        degrees=[]
        node_counter=0
        for m in clustered_data[0]:
            # Creating ego graph for all the actor nodes
            z=nx.ego_graph(A,m)
            # Adding edges from ego graph to U
            U.add_edges_from(z.edges)
            # Adding nodes from ego graph to U 
            U.add_nodes_from(z.nodes)
            # Calculating the degree of U
            degrees.append(nx.degree(U,m))
        for n in U.nodes():
            if 'm' in n:
                # Counter to get the denominator for Cost 2, that is number of movie nodes
                node_counter+=1    
        total_degree=sum(degrees)    
        # Denominator of Cost1. Largest connected graph
        largest_connected_graph = max(nx.connected_components(U), key=len)
        temp_cost1=len(largest_connected_graph)/len(U.nodes)
        temp_cost2=total_degree/node_counter
        # Adding Cost1 and Cost2 for each cluster number in there respective variables
        Cost1+=temp_cost1
        Cost2+=temp_cost2   
    # Finding mean of Cost
    Cost1=Cost1/i
    Cost2=Cost2/i
    Final_Cost=Cost1*Cost2
    All_cost.append(Final_Cost)
print(All_cost)

Best_cluster_index=All_cost.index(max(All_cost))
print("Best Cluster Number is: ",number_of_cluster[Best_cluster_index])

___________________________________________________________________________________________________________________________________________________________________
Training With Best Cluster

Data_in_cluster=[]
clustered_data=[]
Best_cluster=number_of_cluster[Best_cluster_index]
algo =KMeans(n_clusters=Best_cluster)
C=algo.fit(model[actors])
cluster_label=algo.labels_
clusters_data={}
for i,j in zip(actors,C.labels_):
    clusters_data.setdefault(j+1, []).append(i)
for l in clusters_data.keys():
    clustered_data.append(clusters_data.get(l))
    #Data_in_cluster.append(clustered_data)
    
______________________________________________________________________________________________________________________________________________________________________
## Reducing Dimension

from sklearn.manifold import TSNE
transform = TSNE #PCA
trans = transform(n_components=2)
node_embeddings_2d = trans.fit_transform(model[actors])

______________________________________________________________________________________________________________________________________________________________________
## Visualizing Actor Nodes In Clusters


import numpy as np
# draw the points

label_map = { l: i for i, l in enumerate(np.unique(cluster_label))}
node_colours = [ label_map[target] for target in cluster_label]

plt.figure(figsize=(20,16))
plt.axes().set(aspect="equal")
plt.scatter(node_embeddings_2d[:,0], 
            node_embeddings_2d[:,1], 
            c=node_colours, alpha=0.3)
plt.title('{} visualization of node embeddings'.format(transform.__name__))

plt.show()

______________________________________________________________________________________________________________________________________________________________________
## Same Code For Movie Nodes

All_cost=[]
Sorted_cost=[]
number_of_cluster = [3, 5 ,10, 30, 50, 100, 200, 500]
for index,i in enumerate(number_of_cluster):
    Cost1=0
    Cost2=0
    algo =KMeans(n_clusters=i)
    C=algo.fit(model[movies])
    clusters_data={}
    for j,k in zip(actors,C.labels_):
        clusters_data.setdefault(k+1, []).append(j)
    for l in clusters_data.keys():
        clustered_data=[]
        clustered_data.append(clusters_data.get(l))    
        U=nx.Graph()
        degrees=[]
        node_counter=0
        for m in clustered_data[0]:
            z=nx.ego_graph(A,m)
            U.add_edges_from(z.edges)
            U.add_nodes_from(z.nodes)
            degrees.append(nx.degree(U,m))
            #if 'm' in z.nodes():
            #    node_counter+=1
        for n in U.nodes():
            if 'a' in n:
                node_counter+=1    
        total_degree=sum(degrees)    
        largest_connected_graph = max(nx.connected_components(U), key=len)
        temp_cost1=len(largest_connected_graph)/len(U.nodes)
        temp_cost2=total_degree/node_counter
        Cost1+=temp_cost1
        Cost2+=temp_cost2   
    Cost1=Cost1/i
    Cost2=Cost2/i
    Final_Cost=Cost1*Cost2
    All_cost.append(Final_Cost)
print(All_cost)


Best_cluster_index=All_cost.index(max(All_cost))
print("Best Cluster Number is: ",number_of_cluster[Best_cluster_index])


______________________________________________________________________________________________________________________________________________________________________
## Training With Best Cluster Number

Data_in_cluster=[]
clustered_data=[]
Best_cluster=number_of_cluster[Best_cluster_index]
algo =KMeans(n_clusters=Best_cluster)
C=algo.fit(model[movies])
cluster_label=algo.labels_
clusters_data={}
for i,j in zip(actors,C.labels_):
    clusters_data.setdefault(j+1, []).append(i)
for l in clusters_data.keys():
    clustered_data.append(clusters_data.get(l))
    
______________________________________________________________________________________________________________________________________________________________________
## Reducing Dimensions

from sklearn.manifold import TSNE
transform = TSNE #PCA
trans = transform(n_components=2)
node_embeddings_2d = trans.fit_transform(model[movies])

______________________________________________________________________________________________________________________________________________________________________
## Visualizing Actor Nodes

import numpy as np
# draw the points

label_map = { l: i for i, l in enumerate(np.unique(cluster_label))}
node_colours = [ label_map[target] for target in cluster_label]

plt.figure(figsize=(20,16))
plt.axes().set(aspect="equal")
plt.scatter(node_embeddings_2d[:,0], 
            node_embeddings_2d[:,1], 
            c=node_colours, alpha=0.3)
plt.title('{} visualization of node embeddings'.format(transform.__name__))

plt.show()
